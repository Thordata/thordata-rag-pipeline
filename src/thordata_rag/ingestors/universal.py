from thordata import ThordataClient
from markdownify import markdownify as md
from bs4 import BeautifulSoup
import logging

class UniversalIngestor:
    def __init__(self, scraper_token):
        self.client = ThordataClient(scraper_token=scraper_token)

    def _safe_clean_dom(self, html: str) -> str:
        """
        æ¸©å’Œæ¸…æ´—ï¼šåªç§»é™¤ç»å¯¹ä¸éœ€è¦çš„æ ‡ç­¾ï¼Œä¿ç•™ DOM ç»“æ„
        """
        soup = BeautifulSoup(html, "lxml")

        # 1. ç§»é™¤ç»å¯¹åƒåœ¾ (è„šæœ¬ã€æ ·å¼ã€å…ƒæ•°æ®)
        for tag in soup(["script", "style", "noscript", "iframe", "meta", "link", "svg", "button", "input", "form"]):
            tag.decompose()

        # 2. ç§»é™¤æ˜ç¡®çš„å¯¼èˆªå’Œé¡µè„šåŒºåŸŸ (ä½†ä¸è¦åŠ¨ divï¼Œå› ä¸ºæ­£æ–‡å¯èƒ½åœ¨ div é‡Œ)
        for tag in soup(["nav", "footer", "header", "aside"]):
            tag.decompose()

        # 3. ç­–ç•¥ä¼˜åŒ–ï¼šå¦‚æœå­˜åœ¨ <article> æ ‡ç­¾ï¼Œä¼˜å…ˆæå– article
        # è¿™æ˜¯ç»å¤§å¤šæ•°æ–°é—»/åšå®¢ç½‘ç«™çš„æ ‡å‡†æ­£æ–‡å®¹å™¨
        article = soup.find("article")
        if article:
            return str(article)

        return str(soup.body) if soup.body else str(soup)

    def scrape_to_markdown(self, url: str, country: str = None) -> str:
        print(f"ğŸŒ æ­£åœ¨é€šè¿‡ Thordata æŠ“å–ç½‘é¡µ: {url} (Region: {country or 'Auto'})...")
        try:
            # 1. SDK è¯·æ±‚
            kwargs = {
                "url": url,
                "js_render": True,
                "output_format": "html",
                "block_resources": "image,media", # ç¨å¾®æ”¾å®½ï¼Œfont æœ‰æ—¶å½±å“å¸ƒå±€åˆ¤æ–­
                "wait": 5000 
            }
            if country:
                kwargs["country"] = country

            raw_html = str(self.client.universal_scrape(**kwargs))
            
            # 2. æ¸©å’Œæ¸…æ´—
            cleaned_dom = self._safe_clean_dom(raw_html)

            # 3. ç›´æ¥è½¬ Markdown (ä¸å†ä¾èµ– Readabilityï¼Œå› ä¸ºå®ƒåœ¨ç°ä»£ SPA ä¸Šå®¹æ˜“å¤±æ•ˆ)
            # heading_style="ATX" ä¿è¯ç”Ÿæˆ # æ ‡é¢˜
            final_markdown = md(cleaned_dom, heading_style="ATX")
            
            # 4. åå¤„ç†ï¼šå‹ç¼©è¿ç»­ç©ºè¡Œ
            import re
            final_markdown = re.sub(r'\n\s*\n', '\n\n', final_markdown)
            
            print(f"ğŸ“ æå–ç­–ç•¥: Safe Mode (Article/Body) | å†…å®¹é•¿åº¦: {len(final_markdown)} å­—ç¬¦")
            return final_markdown

        except Exception as e:
            return f"Universal Scraping Failed: {str(e)}"